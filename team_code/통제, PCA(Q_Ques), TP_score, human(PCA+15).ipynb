{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA(Q_Ques), 통제변수, tpscore, human(engnat, familysize, hand 제외)\n",
    "# LabelEncoding, Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "run profile1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 세팅\n",
    "# 1) data loading\n",
    "df1 = pd.read_csv('/Users/harryjeong/python_data/maki_train.csv', index_col = 0) \n",
    "df2 = pd.read_csv('/Users/harryjeong/python_data/maki_test_x.csv', index_col = 0)\n",
    "submission = pd.read_csv('/Users/harryjeong/python_data/sample_submission.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) labelencoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label = LabelEncoder()\n",
    "df1['gender_code'] = label.fit_transform(df1['gender'])\n",
    "df1['age_group_code'] = label.fit_transform(df1['age_group'])\n",
    "df1['race_code'] = label.fit_transform(df1['race'])\n",
    "df1['religion_code'] = label.fit_transform(df1['religion'])\n",
    "\n",
    "df2['gender_code'] = label.fit_transform(df2['gender'])\n",
    "df2['age_group_code'] = label.fit_transform(df2['age_group'])\n",
    "df2['race_code'] = label.fit_transform(df2['race'])\n",
    "df2['religion_code'] = label.fit_transform(df2['religion'])\n",
    "\n",
    "# 라벨링한 변수들의 이전 형태는 제거\n",
    "drop = ['gender','age_group','race','religion']\n",
    "df1 = df1.drop(drop, axis = 1)\n",
    "df2 = df2.drop(drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 변수제거1 : Q_Time 제거\n",
    "# Q_Whole : Q 변수 전체\n",
    "Q_Whole = ['QaA', 'QaE', 'QbA', 'QbE', 'QcA', 'QcE', 'QdA', 'QdE', 'QeA',\n",
    "\t\t       'QeE', 'QfA', 'QfE', 'QgA', 'QgE', 'QhA', 'QhE', 'QiA', 'QiE',\n",
    "\t\t       'QjA', 'QjE', 'QkA', 'QkE', 'QlA', 'QlE', 'QmA', 'QmE', 'QnA',\n",
    "\t\t       'QnE', 'QoA', 'QoE', 'QpA', 'QpE', 'QqA', 'QqE', 'QrA', 'QrE',\n",
    "\t\t       'QsA', 'QsE', 'QtA', 'QtE']\n",
    "# Q_Ques : Q 변수 중 질문만\n",
    "Q_Ques = ['QaA', 'QbA', 'QcA', 'QdA', 'QeA',\n",
    "           'QfA', 'QgA', 'QhA', 'QiA', 'QjA', \n",
    "           'QkA', 'QlA', 'QmA', 'QnA', 'QoA', \n",
    "           'QpA', 'QqA', 'QrA', 'QsA', 'QtA']\n",
    "\n",
    "# Q_Time : Q 변수 중 소요시간만\n",
    "Q_Time = ['QaE', 'QbE', 'QcE', 'QdE', 'QeE', 'QfE', 'QgE', 'QhE', 'QiE', 'QkE',\n",
    "          'QjE', 'QlE', 'QmE', 'QnE', 'QoE', 'QpE', 'QqE', 'QrE', 'QsE', 'QtE']\n",
    "\n",
    "# scoring 했기에 기존 데이터는 삭제 (Q_Time)\n",
    "df1 = df1.drop(Q_Time, axis = 1)\n",
    "df2 = df2.drop(Q_Time, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) TP 변수 생성\n",
    "fea2 = ['tp01','tp02','tp03','tp04','tp05','tp06','tp07','tp08','tp09','tp10']\n",
    "df1.loc[:,fea2] = df1.loc[:,fea2].applymap(lambda x: 7 - x)\n",
    "df2.loc[:,fea2] = df2.loc[:,fea2].applymap(lambda x: 7 - x)\n",
    "\n",
    "fea3 = ['tp02','tp04','tp06','tp08','tp10']\n",
    "df1.loc[:,fea3] = df1.loc[:,fea3].applymap(lambda x: 0 if x == 0 else 8 - x)\n",
    "df2.loc[:,fea3] = df2.loc[:,fea3].applymap(lambda x: 0 if x == 0 else 8 - x)\n",
    "\n",
    "# train data 의 TIPI 계산\n",
    "df1['sung']  = (df1.tp03 + df1.tp08)/2\n",
    "df1['chin']= (df1.tp07 + df1.tp02)/2\n",
    "df1['jung'] = (df1.tp09 + df1.tp04)/2\n",
    "df1['kyung'] = (df1.tp05 + df1.tp10)/2\n",
    "df1['why'] =(df1.tp01 + df1.tp06)/2\n",
    "\n",
    "# test data 의 TIPI계산\n",
    "df2['sung']  = (df2.tp03 + df2.tp08)/2\n",
    "df2['chin']= (df2.tp07 + df2.tp02)/2\n",
    "df2['jung'] = (df2.tp09 + df2.tp04)/2\n",
    "df2['kyung'] = (df2.tp05 + df2.tp10)/2\n",
    "df2['why'] =(df2.tp01 + df2.tp06)/2\n",
    "\n",
    "# 기존 tp변수 빼주기 \n",
    "df1 = df1.drop(fea2,axis=1)\n",
    "df2 = df2.drop(fea2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) 변수제거 2 : W 변수 제거\n",
    "w_Whole = ['wf_01', 'wf_02', 'wf_03', 'wr_01', 'wr_02', 'wr_03', 'wr_04', 'wr_05', 'wr_06', 'wr_07',\n",
    "           'wr_08', 'wr_09', 'wr_10', 'wr_11', 'wr_12', 'wr_13']\n",
    "wf_Ques = ['wf_01', 'wf_02', 'wf_03']\n",
    "wr_Ques = ['wr_01', 'wr_02', 'wr_03', 'wr_04', 'wr_05', 'wr_06', 'wr_07',\n",
    "           'wr_08', 'wr_09', 'wr_10', 'wr_11', 'wr_12', 'wr_13']\n",
    "\n",
    "df1 = df1.drop(w_Whole, axis = 1)    # w_Whole 제거\n",
    "df2 = df2.drop(w_Whole, axis = 1)    # w_Whole 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) 독립, 종속변수 분리\n",
    "x = df1.drop('voted', axis = 1)\n",
    "y = df1['voted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 통제변수\n",
    "# => 인구통계학 같은 행만 모아서 로지스틱 회귀분석\n",
    "# 1) 변수 뽑아내기\n",
    "human = ['education', 'engnat', 'married', 'urban', 'gender_code', 'age_group_code',\n",
    "         'race_code', 'religion_code']\n",
    "\n",
    "human_df = x[human]\n",
    "\n",
    "# 인구통계학 변수 통제한 동일행 추출\n",
    "human_df_1 = human_df.groupby(['education', 'religion_code', 'married', \n",
    "                               'urban', 'gender_code', 'age_group_code',\n",
    "                               'race_code']).count().loc[:, ['engnat']]\n",
    "\n",
    "# 동일행은 499개\n",
    "human_df_1[human_df_1['engnat'] == 499]\n",
    "             \n",
    "# 동일행이 가지고 있는 각 컬럼의 값    \n",
    "# education religion_code married urban gender_code age_group_code race_code        \n",
    "# 2         1             1       2     1           1              6         \n",
    "\n",
    "# 위 컬럼 값을 대입하여 499개 행을 찾아냄\n",
    "h_control_index = x.loc[x.education == 2, :].loc[x.religion_code == 1, :].loc[x.married == 1, :].loc[x.urban == 2, :].loc[x.gender_code == 1, :].loc[x.age_group_code == 1, :].loc[x.race_code == 6, :].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) scaling\n",
    "from sklearn.preprocessing import StandardScaler as standard\n",
    "m_sc = standard()\n",
    "m_sc.fit(x)\n",
    "x = DataFrame(m_sc.transform(x), columns = x.columns)\n",
    "df2 = DataFrame(m_sc.transform(df2), columns = df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 전체 데이터에서 499개 행 찾아냄\n",
    "x_h_control = x.loc[h_control_index, :]\n",
    "y_h_control = y.loc[h_control_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) 499개 행 데이터에서 human 변수 제거 for PCA\n",
    "x_h_control = x_h_control.drop(['education', 'religion_code', 'engnat', \n",
    "                                'married', 'urban', 'gender_code',\n",
    "                                'age_group_code', 'race_code'], axis = 1)\n",
    "\n",
    "x = x.drop(['education', 'religion_code', 'engnat', 'married', 'urban',\n",
    "            'gender_code', 'age_group_code', 'race_code'], axis = 1)\n",
    "\n",
    "df2_1 = df2.drop(['education', 'religion_code', 'engnat', 'married', 'urban',\n",
    "                'gender_code', 'age_group_code', 'race_code'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) 499개 행 데이터에서 TP_score 변수 제거 for PCA\n",
    "fea1 = ['sung','chin','jung','kyung','why']\n",
    "\n",
    "x_h_control = x_h_control.drop(fea1, axis = 1)\n",
    "x = x.drop(fea1, axis = 1)\n",
    "df2_1 = df2_1.drop(fea1, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) 499개 행 데이터에서 engnat, hand, familysize 변수 제거 for PCA\n",
    "x_h_control = x_h_control.drop(['hand', 'familysize'], axis = 1)\n",
    "x = x.drop(['hand', 'familysize'], axis = 1)\n",
    "df2_1 = df2_1.drop(['hand', 'familysize'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QaA</th>\n",
       "      <th>QbA</th>\n",
       "      <th>QcA</th>\n",
       "      <th>QdA</th>\n",
       "      <th>QeA</th>\n",
       "      <th>QfA</th>\n",
       "      <th>QgA</th>\n",
       "      <th>QhA</th>\n",
       "      <th>QiA</th>\n",
       "      <th>QjA</th>\n",
       "      <th>QkA</th>\n",
       "      <th>QlA</th>\n",
       "      <th>QmA</th>\n",
       "      <th>QnA</th>\n",
       "      <th>QoA</th>\n",
       "      <th>QpA</th>\n",
       "      <th>QqA</th>\n",
       "      <th>QrA</th>\n",
       "      <th>QsA</th>\n",
       "      <th>QtA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>-0.108222</td>\n",
       "      <td>-1.216035</td>\n",
       "      <td>-0.462702</td>\n",
       "      <td>1.198646</td>\n",
       "      <td>-0.232219</td>\n",
       "      <td>-0.124678</td>\n",
       "      <td>0.952880</td>\n",
       "      <td>-0.902214</td>\n",
       "      <td>-0.106424</td>\n",
       "      <td>-1.157452</td>\n",
       "      <td>0.135564</td>\n",
       "      <td>0.587869</td>\n",
       "      <td>-1.09781</td>\n",
       "      <td>-0.429663</td>\n",
       "      <td>-1.501785</td>\n",
       "      <td>-1.390692</td>\n",
       "      <td>0.113603</td>\n",
       "      <td>0.825990</td>\n",
       "      <td>-1.769516</td>\n",
       "      <td>-0.805533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>-0.943687</td>\n",
       "      <td>0.699521</td>\n",
       "      <td>0.235877</td>\n",
       "      <td>-0.717773</td>\n",
       "      <td>-0.232219</td>\n",
       "      <td>-0.124678</td>\n",
       "      <td>0.952880</td>\n",
       "      <td>-0.902214</td>\n",
       "      <td>0.568465</td>\n",
       "      <td>0.311835</td>\n",
       "      <td>-1.321593</td>\n",
       "      <td>0.587869</td>\n",
       "      <td>0.35661</td>\n",
       "      <td>0.249221</td>\n",
       "      <td>-1.501785</td>\n",
       "      <td>0.623099</td>\n",
       "      <td>0.825689</td>\n",
       "      <td>-0.578142</td>\n",
       "      <td>1.139738</td>\n",
       "      <td>0.508885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>0.727242</td>\n",
       "      <td>0.699521</td>\n",
       "      <td>0.934456</td>\n",
       "      <td>0.240436</td>\n",
       "      <td>-0.232219</td>\n",
       "      <td>-0.124678</td>\n",
       "      <td>0.952880</td>\n",
       "      <td>1.836017</td>\n",
       "      <td>0.568465</td>\n",
       "      <td>-1.157452</td>\n",
       "      <td>0.864143</td>\n",
       "      <td>0.587869</td>\n",
       "      <td>1.08382</td>\n",
       "      <td>0.928105</td>\n",
       "      <td>1.207512</td>\n",
       "      <td>-1.390692</td>\n",
       "      <td>0.113603</td>\n",
       "      <td>1.528056</td>\n",
       "      <td>0.412424</td>\n",
       "      <td>-0.805533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>-0.943687</td>\n",
       "      <td>0.699521</td>\n",
       "      <td>0.934456</td>\n",
       "      <td>-0.717773</td>\n",
       "      <td>1.228498</td>\n",
       "      <td>2.099789</td>\n",
       "      <td>-0.371111</td>\n",
       "      <td>0.466901</td>\n",
       "      <td>0.568465</td>\n",
       "      <td>1.046478</td>\n",
       "      <td>0.135564</td>\n",
       "      <td>0.587869</td>\n",
       "      <td>-0.37060</td>\n",
       "      <td>-1.108547</td>\n",
       "      <td>0.530188</td>\n",
       "      <td>1.294363</td>\n",
       "      <td>-1.310567</td>\n",
       "      <td>-1.280208</td>\n",
       "      <td>1.139738</td>\n",
       "      <td>1.166094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>-0.943687</td>\n",
       "      <td>0.061002</td>\n",
       "      <td>0.235877</td>\n",
       "      <td>-0.717773</td>\n",
       "      <td>0.498140</td>\n",
       "      <td>-0.124678</td>\n",
       "      <td>-0.371111</td>\n",
       "      <td>-0.902214</td>\n",
       "      <td>-1.456203</td>\n",
       "      <td>1.046478</td>\n",
       "      <td>-0.593014</td>\n",
       "      <td>0.587869</td>\n",
       "      <td>1.08382</td>\n",
       "      <td>-1.108547</td>\n",
       "      <td>1.207512</td>\n",
       "      <td>1.294363</td>\n",
       "      <td>-1.310567</td>\n",
       "      <td>-1.280208</td>\n",
       "      <td>1.139738</td>\n",
       "      <td>0.508885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45097</th>\n",
       "      <td>-0.943687</td>\n",
       "      <td>1.338040</td>\n",
       "      <td>0.934456</td>\n",
       "      <td>-0.717773</td>\n",
       "      <td>-0.962578</td>\n",
       "      <td>-0.866167</td>\n",
       "      <td>-1.033107</td>\n",
       "      <td>1.151459</td>\n",
       "      <td>-1.456203</td>\n",
       "      <td>1.046478</td>\n",
       "      <td>-2.050171</td>\n",
       "      <td>0.587869</td>\n",
       "      <td>0.35661</td>\n",
       "      <td>-0.429663</td>\n",
       "      <td>1.207512</td>\n",
       "      <td>1.294363</td>\n",
       "      <td>-1.310567</td>\n",
       "      <td>0.123924</td>\n",
       "      <td>1.139738</td>\n",
       "      <td>1.166094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45102</th>\n",
       "      <td>1.562707</td>\n",
       "      <td>0.699521</td>\n",
       "      <td>0.934456</td>\n",
       "      <td>-0.717773</td>\n",
       "      <td>-0.962578</td>\n",
       "      <td>2.099789</td>\n",
       "      <td>1.614876</td>\n",
       "      <td>1.151459</td>\n",
       "      <td>1.243355</td>\n",
       "      <td>0.311835</td>\n",
       "      <td>0.864143</td>\n",
       "      <td>0.587869</td>\n",
       "      <td>0.35661</td>\n",
       "      <td>1.606989</td>\n",
       "      <td>-1.501785</td>\n",
       "      <td>-1.390692</td>\n",
       "      <td>0.113603</td>\n",
       "      <td>0.825990</td>\n",
       "      <td>0.412424</td>\n",
       "      <td>-1.462741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45167</th>\n",
       "      <td>-0.943687</td>\n",
       "      <td>0.699521</td>\n",
       "      <td>0.235877</td>\n",
       "      <td>0.240436</td>\n",
       "      <td>-0.232219</td>\n",
       "      <td>-0.866167</td>\n",
       "      <td>-0.371111</td>\n",
       "      <td>0.466901</td>\n",
       "      <td>-0.781314</td>\n",
       "      <td>-0.422809</td>\n",
       "      <td>-0.593014</td>\n",
       "      <td>0.587869</td>\n",
       "      <td>0.35661</td>\n",
       "      <td>-0.429663</td>\n",
       "      <td>0.530188</td>\n",
       "      <td>-0.719428</td>\n",
       "      <td>0.113603</td>\n",
       "      <td>-0.578142</td>\n",
       "      <td>0.412424</td>\n",
       "      <td>0.508885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45288</th>\n",
       "      <td>-0.943687</td>\n",
       "      <td>-0.577517</td>\n",
       "      <td>0.934456</td>\n",
       "      <td>-0.717773</td>\n",
       "      <td>0.498140</td>\n",
       "      <td>-0.866167</td>\n",
       "      <td>-1.033107</td>\n",
       "      <td>-0.902214</td>\n",
       "      <td>0.568465</td>\n",
       "      <td>0.311835</td>\n",
       "      <td>0.864143</td>\n",
       "      <td>0.587869</td>\n",
       "      <td>0.35661</td>\n",
       "      <td>0.928105</td>\n",
       "      <td>-1.501785</td>\n",
       "      <td>0.623099</td>\n",
       "      <td>0.113603</td>\n",
       "      <td>0.123924</td>\n",
       "      <td>0.412424</td>\n",
       "      <td>-1.462741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45361</th>\n",
       "      <td>-0.108222</td>\n",
       "      <td>-0.577517</td>\n",
       "      <td>-1.161281</td>\n",
       "      <td>0.240436</td>\n",
       "      <td>-0.962578</td>\n",
       "      <td>-0.124678</td>\n",
       "      <td>0.952880</td>\n",
       "      <td>1.151459</td>\n",
       "      <td>-0.781314</td>\n",
       "      <td>-0.422809</td>\n",
       "      <td>0.135564</td>\n",
       "      <td>0.587869</td>\n",
       "      <td>-1.09781</td>\n",
       "      <td>-0.429663</td>\n",
       "      <td>0.530188</td>\n",
       "      <td>-0.719428</td>\n",
       "      <td>-0.598482</td>\n",
       "      <td>0.825990</td>\n",
       "      <td>0.412424</td>\n",
       "      <td>-0.148324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            QaA       QbA       QcA       QdA       QeA       QfA       QgA  \\\n",
       "121   -0.108222 -1.216035 -0.462702  1.198646 -0.232219 -0.124678  0.952880   \n",
       "221   -0.943687  0.699521  0.235877 -0.717773 -0.232219 -0.124678  0.952880   \n",
       "431    0.727242  0.699521  0.934456  0.240436 -0.232219 -0.124678  0.952880   \n",
       "681   -0.943687  0.699521  0.934456 -0.717773  1.228498  2.099789 -0.371111   \n",
       "682   -0.943687  0.061002  0.235877 -0.717773  0.498140 -0.124678 -0.371111   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "45097 -0.943687  1.338040  0.934456 -0.717773 -0.962578 -0.866167 -1.033107   \n",
       "45102  1.562707  0.699521  0.934456 -0.717773 -0.962578  2.099789  1.614876   \n",
       "45167 -0.943687  0.699521  0.235877  0.240436 -0.232219 -0.866167 -0.371111   \n",
       "45288 -0.943687 -0.577517  0.934456 -0.717773  0.498140 -0.866167 -1.033107   \n",
       "45361 -0.108222 -0.577517 -1.161281  0.240436 -0.962578 -0.124678  0.952880   \n",
       "\n",
       "            QhA       QiA       QjA       QkA       QlA      QmA       QnA  \\\n",
       "121   -0.902214 -0.106424 -1.157452  0.135564  0.587869 -1.09781 -0.429663   \n",
       "221   -0.902214  0.568465  0.311835 -1.321593  0.587869  0.35661  0.249221   \n",
       "431    1.836017  0.568465 -1.157452  0.864143  0.587869  1.08382  0.928105   \n",
       "681    0.466901  0.568465  1.046478  0.135564  0.587869 -0.37060 -1.108547   \n",
       "682   -0.902214 -1.456203  1.046478 -0.593014  0.587869  1.08382 -1.108547   \n",
       "...         ...       ...       ...       ...       ...      ...       ...   \n",
       "45097  1.151459 -1.456203  1.046478 -2.050171  0.587869  0.35661 -0.429663   \n",
       "45102  1.151459  1.243355  0.311835  0.864143  0.587869  0.35661  1.606989   \n",
       "45167  0.466901 -0.781314 -0.422809 -0.593014  0.587869  0.35661 -0.429663   \n",
       "45288 -0.902214  0.568465  0.311835  0.864143  0.587869  0.35661  0.928105   \n",
       "45361  1.151459 -0.781314 -0.422809  0.135564  0.587869 -1.09781 -0.429663   \n",
       "\n",
       "            QoA       QpA       QqA       QrA       QsA       QtA  \n",
       "121   -1.501785 -1.390692  0.113603  0.825990 -1.769516 -0.805533  \n",
       "221   -1.501785  0.623099  0.825689 -0.578142  1.139738  0.508885  \n",
       "431    1.207512 -1.390692  0.113603  1.528056  0.412424 -0.805533  \n",
       "681    0.530188  1.294363 -1.310567 -1.280208  1.139738  1.166094  \n",
       "682    1.207512  1.294363 -1.310567 -1.280208  1.139738  0.508885  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "45097  1.207512  1.294363 -1.310567  0.123924  1.139738  1.166094  \n",
       "45102 -1.501785 -1.390692  0.113603  0.825990  0.412424 -1.462741  \n",
       "45167  0.530188 -0.719428  0.113603 -0.578142  0.412424  0.508885  \n",
       "45288 -1.501785  0.623099  0.113603  0.123924  0.412424 -1.462741  \n",
       "45361  0.530188 -0.719428 -0.598482  0.825990  0.412424 -0.148324  \n",
       "\n",
       "[499 rows x 20 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_h_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. PCA\n",
    "# 1) 인공변수 생성\n",
    "vscore = []\n",
    "for i in [0.7, 0.75, 0.8, 0.85, 0.9, 0.95] :\n",
    "    from sklearn.decomposition import PCA\n",
    "    m_pca = PCA(n_components = i)                 \n",
    "    m_pca.fit(x_h_control)                           # 499개의 통제된 데이터의 Q_Ques만 가지고 fitting\n",
    "    x_pca = m_pca.transform(x)                       # 위 fitting을 전체 Q_Ques에 적용하여 인공변수 뽑아냄\n",
    "    df2_pca = m_pca.transform(df2_1)                 # df2에도 똑같이 적용\n",
    "    \n",
    "    # 2) 인공변수 대입\n",
    "    # 인공변수만을 가지는 데이터프레임 d1, d2 생성\n",
    "    s1_columns = np.arange(1, len(x_pca[1]) + 1)\n",
    "    d1 = DataFrame(x_pca, columns = s1_columns)\n",
    "    d2 = DataFrame(df2_pca, columns = s1_columns)\n",
    "\n",
    "    # tpscore, human(engnat, familysize, hand 제외) 컬럼을 가지는 데이터프레임 col1, col2 생성\n",
    "    col1 = df1.drop(['voted'], axis = 1).drop(Q_Ques, axis = 1)\n",
    "    col2 = df2.drop(Q_Ques, axis = 1)\n",
    "\n",
    "    c1 = d1.columns.tolist()\n",
    "    c2 = col1.columns.tolist()\n",
    "    c3 = c1 + c2\n",
    "\n",
    "    # d1, d2에 나머지 컬럼데이터 추가\n",
    "    df1_new = DataFrame(np.hstack([d1, col1]), columns = c3)\n",
    "    # df1_new['y'] = y => automl용\n",
    "\n",
    "    df2_new = DataFrame(np.hstack([d2, col2]), columns = c3)    \n",
    "    \n",
    "    # 4. RF 모델적용 \n",
    "    # 1) test, train split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_x, test_x, train_y, test_y = train_test_split(df1_new,              \n",
    "                                                    y,               \n",
    "                                                    train_size = 0.7, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "    # 2) 모델링\n",
    "    m_rf = rf(random_state = 0)\n",
    "    m_rf.fit(train_x, train_y)\n",
    "    vscore.append(m_rf.score(test_x, test_y))    # 0.696"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6944363103953148,\n",
       " 0.6956808199121522,\n",
       " 0.6962664714494875,\n",
       " 0.6913616398243045,\n",
       " 0.6943631039531479,\n",
       " 0.6933382137628111]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11c073cd0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([0.7, 0.75, 0.8, 0.85, 0.9, 0.95], vscore, label = 'vscore')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 최적의 차원개수 확보 -> 매개변수 튜닝\n",
    "# 3-1) 인공변수 생성\n",
    "from sklearn.decomposition import PCA\n",
    "m_pca = PCA(n_components = 0.80)                 \n",
    "m_pca.fit(x_h_control)                           # 499개의 통제된 데이터의 Q_Ques만 가지고 fitting\n",
    "x_pca = m_pca.transform(x)                       # 위 fitting을 전체 Q_Ques에 적용하여 인공변수 뽑아냄\n",
    "df2_pca = m_pca.transform(df2_1)                 # df2에도 똑같이 적용\n",
    "    \n",
    "# 3-2) 인공변수 대입\n",
    "# 인공변수만을 가지는 데이터프레임 d1, d2 생성\n",
    "s1_columns = np.arange(1, len(x_pca[1]) + 1)\n",
    "d1 = DataFrame(x_pca, columns = s1_columns)\n",
    "d2 = DataFrame(df2_pca, columns = s1_columns)\n",
    "\n",
    "# tpscore, human(engnat, familysize, hand 제외) 컬럼을 가지는 데이터프레임 col1, col2 생성\n",
    "col1 = df1.drop(['voted'], axis = 1).drop(Q_Ques, axis = 1)\n",
    "col2 = df2.drop(Q_Ques, axis = 1)\n",
    "\n",
    "c1 = d1.columns.tolist()\n",
    "c2 = col1.columns.tolist()\n",
    "c3 = c1 + c2\n",
    "\n",
    "# d1, d2에 나머지 컬럼데이터 추가\n",
    "df1_new = DataFrame(np.hstack([d1, col1]), columns = c3)\n",
    "# df1_new['y'] = y => automl용\n",
    "df2_new = DataFrame(np.hstack([d2, col2]), columns = c3)\n",
    "\n",
    "# 4. RF 모델적용 \n",
    "# 1) test, train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "trainval_x, test_x, trainval_y, test_y = train_test_split(df1_new,              \n",
    "                                                          y,               \n",
    "                                                          train_size = 0.7, \n",
    "                                                          random_state = 0)\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(trainval_x,              \n",
    "                                                  trainval_y,               \n",
    "                                                  train_size = 0.7, \n",
    "                                                  random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 매개변수 튜닝 (그리드 서치)\n",
    "# 모델링\n",
    "m_rf = rf(random_state = 0)\n",
    "# 3-1) 매개변수 조합 생성\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "m_rf = rf(random_state = 0)\n",
    "v_params = {'min_samples_split' : np.arange(2, 11),\n",
    "            'max_features' : np.arange(1, 31)}\n",
    "\n",
    "# 3-2) 그리드 서치 모델 생성\n",
    "m_grid = GridSearchCV(m_rf,           # 적용 모델\n",
    "                      v_params,       # 매개변수 조합 (딕셔너리)\n",
    "                      cv = 5)\n",
    "\n",
    "# 3-3) 그리드 서치에 의한 모델 학습\n",
    "m_grid.fit(trainval_x, trainval_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-4) 결과 확인\n",
    "dir(m_grid)\n",
    "m_grid.best_score_    # 베스트 매개변수 값을 갖는 평가 점수 => 0.962\n",
    "m_grid.best_params_   # {'max_features': 1, 'min_samples_split': 5}\n",
    "\n",
    "df_result = DataFrame(m_grid.cv_results_)\n",
    "df_result.T    # 여기서 test_score들은 우리가 아는 test score가 아니고, validation score라고 생각하면 됨\n",
    "\n",
    "df_result.T.iloc[:, 0]    # 첫 번째 매개변수 셋 결과\n",
    "\n",
    "# cv = 5이기 때문에 아래처럼 5회 진행\n",
    "# split0_test_score                                              0.94186\n",
    "# split1_test_score                                             0.952941\n",
    "# split2_test_score                                             0.929412\n",
    "# split3_test_score                                             0.988235\n",
    "# split4_test_score                                             0.988235\n",
    "\n",
    "# 3-5) 최종 평가\n",
    "m_grid.score(test_x, test_y)    # 0.951 => 모델 자체에 best params가 저장되어 있음\n",
    "\n",
    "# 3-6) 그리드 서치 결과 시각화\n",
    "df_result.mean_test_score    # 교차 검증의 결과 (5개의 점수에 대한 평균)\n",
    "arr_score = np.array(df_result.mean_test_score).reshape(30, 9)    \n",
    "# reshape(max_features, min_samples) => reshape은 행우선 순위로 배치 되기 때문에\n",
    "df_result.loc[:, ['params', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) 최적의 차원 개수로 실제 데이터 셋에 적용 및 제출 => 0.85\n",
    "# 3-1) 인공변수 생성\n",
    "from sklearn.decomposition import PCA\n",
    "m_pca = PCA(n_components = 0.80)                 \n",
    "m_pca.fit(x_h_control)                           # 499개의 통제된 데이터의 Q_Ques만 가지고 fitting\n",
    "x_pca = m_pca.transform(x)                       # 위 fitting을 전체 Q_Ques에 적용하여 인공변수 뽑아냄\n",
    "df2_pca = m_pca.transform(df2_1)                 # df2에도 똑같이 적용\n",
    "    \n",
    "# 3-2) 인공변수 대입\n",
    "# 인공변수만을 가지는 데이터프레임 d1, d2 생성\n",
    "s1_columns = np.arange(1, len(x_pca[1]) + 1)\n",
    "d1 = DataFrame(x_pca, columns = s1_columns)\n",
    "d2 = DataFrame(df2_pca, columns = s1_columns)\n",
    "\n",
    "# tpscore, human(engnat, familysize, hand 제외) 컬럼을 가지는 데이터프레임 col1, col2 생성\n",
    "col1 = df1.drop(['voted'], axis = 1).drop(Q_Ques, axis = 1)\n",
    "col2 = df2.drop(Q_Ques, axis = 1)\n",
    "\n",
    "c1 = d1.columns.tolist()\n",
    "c2 = col1.columns.tolist()\n",
    "c3 = c1 + c2\n",
    "\n",
    "# d1, d2에 나머지 컬럼데이터 추가\n",
    "df1_new = DataFrame(np.hstack([d1, col1]), columns = c3)\n",
    "# df1_new['y'] = y => automl용\n",
    "df2_new = DataFrame(np.hstack([d2, col2]), columns = c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-3) 모델링\n",
    "m_rf = rf(random_state = 0)\n",
    "m_rf.fit(df1_new, y)\n",
    "\n",
    "m_rf.predict(df2_new)\n",
    "\n",
    "pred_y = m_rf.predict(df2_new)\n",
    "submission['voted'] = pred_y\n",
    "\n",
    "submission.to_csv('/Users/harryjeong/sample_submission_pca_tp_human.csv')    # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
